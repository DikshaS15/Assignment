{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Questions\n",
        "\n",
        "##Theoretical"
      ],
      "metadata": {
        "id": "Q2n3kwgR9rbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.What is a Decision Tree, and how does it work ?\n",
        "\n",
        "Ans-1. A decision tree is a powerful and versatile tool used in various fields, including machine learning, data mining, and decision analysis. Here's a breakdown of what it is and how it works:\n",
        "\n",
        "####**What is a Decision Tree?**\n",
        "\n",
        "* **Visual Representation:**\n",
        "\n",
        "* A decision tree is essentially a flowchart-like structure that models decisions and their possible consequences.\n",
        "\n",
        "* It visually represents a series of decisions and their potential outcomes.\n",
        "\n",
        "* **Decision-Making Tool:**\n",
        "\n",
        "* It helps in making informed decisions by breaking down complex problems into simpler, more manageable ones.\n",
        "\n",
        "* **Machine Learning Algorithm:**\n",
        "\n",
        "* In machine learning, decision trees are used as predictive models to classify or predict outcomes based on input data.\n",
        "\n",
        "####How it Works:\n",
        "\n",
        "1. **Structure:**\n",
        "\n",
        "* A decision tree consists of nodes and branches.\n",
        "\n",
        "* **Root Node:** The starting point of the tree, representing the initial decision or question.\n",
        "\n",
        "* **Internal Nodes:** Represent decision points, where the data is split based on certain attributes.\n",
        "\n",
        "* **Branches:** Represent the possible outcomes of each decision.\n",
        "\n",
        "* **Leaf Nodes (Terminal Nodes):** Represent the final outcomes or predictions.\n",
        "\n",
        "2. **Decision Process:**\n",
        "\n",
        "* The tree works by recursively partitioning the data based on the values of different attributes.\n",
        "\n",
        "* At each internal node, a test is performed on an attribute, and the data is split into subsets based on the test result.\n",
        "\n",
        "* This process continues until a leaf node is reached, which represents the predicted outcome.\n",
        "\n",
        "3. **Splitting Criteria:**\n",
        "\n",
        "* Algorithms use various metrics to determine the best attribute to split on at each node. Common metrics include:\n",
        "\n",
        "* **Gini impurity:** Measures the impurity of a set of data.\n",
        "\n",
        "* **Entropy:** Measures the disorder or randomness of a set of data.\n",
        "\n",
        "* **Information gain:** Measures the reduction in entropy after a split.\n",
        "\n",
        "####Types of Decision Trees:\n",
        "\n",
        "* **Classification Trees:** Used when the predicted outcome is a categorical variable (e.g., yes/no, red/blue).\n",
        "\n",
        "* **Regression Trees:** Used when the predicted outcome is a continuous variable (e.g., price, temperature).\n",
        "\n",
        "####Key Advantages:\n",
        "\n",
        "* **Easy to Understand:** Decision trees are highly interpretable, making it easy to understand how decisions are made.\n",
        "\n",
        "* **Handles Both Categorical and Numerical Data:** They can work with various types of data.\n",
        "\n",
        "* **Visual Representation:** The tree structure provides a clear and intuitive visualization of the decision-making process.\n",
        "\n",
        "####Key Considerations:\n",
        "\n",
        "* **Overfitting:** Decision trees can become overly complex and overfit the training data, leading to poor performance on new data.\n",
        "\n",
        "* **Instability:** Small changes in the data can lead to significant changes in the tree structure.\n",
        "\n",
        "In essence, decision trees provide a clear and structured way to analyze decisions and predict outcomes, making them valuable tools in various fields.\n"
      ],
      "metadata": {
        "id": "1BNOV_fO92Uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.What are impurity measures in Decision Trees ?\n",
        "\n",
        "Ans-2. In the context of decision trees, \"impurity measures\" are crucial metrics used to determine the best way to split the data at each node. They quantify how mixed or \"impure\" a set of data is with respect to the class labels. The goal is to create splits that result in subsets of data that are as \"pure\" as possible, meaning they primarily contain instances of a single class.\n",
        "\n",
        "Here's a breakdown of the key impurity measures:\n",
        "\n",
        "1. **Gini Impurity:**\n",
        "\n",
        "####What it is:\n",
        "\n",
        "* The Gini impurity measures the probability of incorrectly classifying a randomly chosen element in a dataset if it were randomly labeled according to the distribution of labels in the subset.\n",
        "\n",
        "* A Gini impurity of 0 means that all elements belong to the same class (perfect purity).\n",
        "\n",
        "* A higher Gini impurity indicates a more mixed set of classes.\n",
        "\n",
        "####How it's used:\n",
        "\n",
        "* Decision tree algorithms use the Gini impurity to evaluate potential splits and choose the one that results in the lowest Gini impurity in the resulting subsets.\n",
        "\n",
        "2. **Entropy:**\n",
        "\n",
        "####What it is:\n",
        "\n",
        "* Entropy measures the disorder or randomness of a dataset. In the context of decision trees, it quantifies the uncertainty of the class labels in a node.\n",
        "\n",
        "* A high entropy value indicates a high degree of disorder (mixed classes), while a low entropy value indicates a more ordered set (predominantly one class).\n",
        "\n",
        "####How it's used:\n",
        "\n",
        "* Similar to the Gini impurity, entropy is used to find the best splits that reduce uncertainty and create more homogeneous subsets.\n",
        "\n",
        "3. **Information Gain:**\n",
        "\n",
        "####What it is:\n",
        "\n",
        "* Information gain is derived from entropy. It measures the reduction in entropy achieved by splitting a dataset on a particular attribute.\n",
        "\n",
        "* It essentially quantifies how much \"information\" is gained about the class labels by partitioning the data.\n",
        "\n",
        "####How it's used:\n",
        "\n",
        "* Decision tree algorithms aim to maximize information gain, selecting the attribute that provides the greatest reduction in entropy.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "* These impurity measures help decision tree algorithms make intelligent decisions about how to partition data, leading to more accurate and effective predictive models.\n",
        "\n",
        "* They provide a way to numerically evaluate the quality of a potential split in the data.\n",
        "\n",
        "* By minimizing impurity, the algorithm is working to create nodes that contain primarily one class of data."
      ],
      "metadata": {
        "id": "4h-XSulV_pvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.What is the mathematical formula for Gini Impurity ?\n",
        "\n",
        "Ans-3. The mathematical formula for Gini impurity is relatively straightforward. Here's how it's expressed:\n",
        "\n",
        "**General Formula:**\n",
        "\n",
        "If you have a dataset with 'n' classes, the Gini impurity is calculated as:\n",
        "\n",
        "    Gini = 1 - Σ (p_i)^2\n",
        "\n",
        "Where:\n",
        "\n",
        "* Σ represents the sum.\n",
        "\n",
        "* p_i is the probability of an element belonging to class 'i'.\n",
        "\n",
        "####Breaking it down:\n",
        "\n",
        "1. **Probability Calculation:**\n",
        "\n",
        "* For each class, you calculate the probability of an element belonging to that class. This is typically done by dividing the number of elements in that class by the total number of elements in the dataset.\n",
        "\n",
        "2. **Squaring Probabilities:**\n",
        "\n",
        "* You then square each of these probabilities.\n",
        "\n",
        "3. **Summation:**\n",
        "\n",
        "* You sum up all the squared probabilities.\n",
        "\n",
        "4. **Subtraction:**\n",
        "\n",
        "* Finally, you subtract this sum from 1.\n",
        "\n",
        "####Example with two classes:\n",
        "\n",
        "* If you have a dataset with two classes (e.g., \"yes\" and \"no\"), the formula becomes:\n",
        "\n",
        "    Gini = 1 - (p_yes^2 + p_no^2)\n",
        "\n",
        "Where:\n",
        "\n",
        "* p_yes is the probability of \"yes\".\n",
        "\n",
        "* p_no is the probability of \"no\".\n",
        "\n",
        "####Key points:\n",
        "\n",
        "* The Gini impurity ranges from 0 to 0.5.\n",
        "\n",
        "* A Gini impurity of 0 indicates perfect purity (all elements belong to the same class).\n",
        "\n",
        "* A Gini impurity of 0.5 indicates maximum impurity (the classes are evenly distributed)."
      ],
      "metadata": {
        "id": "uIqXXXXZBbFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.What is the mathematical formula for Entropy\t?\n",
        "\n",
        "Ans-4. The mathematical formula for entropy, particularly as it's used in decision trees, quantifies the amount of disorder or uncertainty in a dataset. Here's the breakdown:\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "* The entropy (H) of a dataset (S) is calculated as:\n",
        "\n",
        "      H(S) = - Σ pi * log2(pi)\n",
        "\n",
        "Where:\n",
        "\n",
        "* H(S) is the entropy of the dataset S.\n",
        "\n",
        "* Σ represents the sum over all classes.\n",
        "\n",
        "* pi is the probability of an element belonging to class 'i'.\n",
        "\n",
        "* log2 is the logarithm base 2.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1. **Probability Calculation (pi):**\n",
        "\n",
        "* For each distinct class within the dataset, you determine the proportion of instances that belong to that class. This proportion represents the probability (pi) of encountering an instance of that class.\n",
        "\n",
        "2. **Logarithmic Calculation (log2(pi)):**\n",
        "\n",
        "* You take the base-2 logarithm of each class probability. This logarithm reflects the amount of information required to represent that class.\n",
        "\n",
        "3. **Multiplication and Summation:**\n",
        "\n",
        "* You multiply each probability (pi) by its corresponding logarithm (log2(pi)).\n",
        "Then, you sum up these products for all classes.\n",
        "\n",
        "4. **Negation:**\n",
        "\n",
        "* Finally, you negate the entire sum. This ensures that the entropy value is non-negative.\n",
        "\n",
        "####Key Points:\n",
        "\n",
        "* Entropy values range from 0 to 1 (in the case of binary classification).\n",
        "\n",
        "* An entropy of 0 indicates perfect order (all instances belong to the same class).\n",
        "\n",
        "* An entropy of 1 (in binary classification) indicates maximum disorder (classes are evenly distributed).\n",
        "\n",
        "* The use of log base 2, results in the measurement of information in bits.\n",
        "\n"
      ],
      "metadata": {
        "id": "1APkmG-JCV8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.What is Information Gain, and how is it used in Decision Trees ?\n",
        "\n",
        "Ans-5. Information gain is a fundamental concept in decision tree algorithms, particularly when it comes to determining the best way to split data at each node. Here's a breakdown:\n",
        "\n",
        "**What is Information Gain?**\n",
        "\n",
        "* **Reduction in Entropy:**\n",
        "\n",
        "* Information gain measures the reduction in entropy (uncertainty) achieved by splitting a dataset on a particular attribute.\n",
        "\n",
        "* In simpler terms, it tells you how much \"information\" you gain about the target variable by knowing the value of a specific feature.\n",
        "\n",
        "* **Attribute Selection:**\n",
        "\n",
        "* Decision tree algorithms use information gain to select the attribute that provides the most significant reduction in entropy, as this attribute is considered the most informative for classifying the data.\n",
        "\n",
        "####How it's Used in Decision Trees:\n",
        "\n",
        "1. **Entropy Calculation:**\n",
        "\n",
        "* First, the entropy of the current dataset (before any split) is calculated. This represents the initial level of uncertainty.\n",
        "\n",
        "2. **Splitting and Entropy Calculation:**\n",
        "\n",
        "* For each attribute, the dataset is hypothetically split into subsets based on the attribute's values.\n",
        "\n",
        "* The entropy of each resulting subset is calculated.\n",
        "\n",
        "3. **Weighted Average Entropy:**\n",
        "\n",
        "* A weighted average of the subset entropies is calculated, where the weights are determined by the proportion of data points in each subset.\n",
        "\n",
        "4. **Information Gain Calculation:**\n",
        "\n",
        "* The information gain is then calculated by subtracting the weighted average entropy of the subsets from the original entropy of the dataset.\n",
        "\n",
        "5. **Attribute Selection:**\n",
        "\n",
        "* The attribute with the highest information gain is selected as the best attribute to split on at that node.\n",
        "\n",
        "* This process is repeated recursively for each subsequent node until the tree is complete.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "* Information gain helps the decision tree algorithm to prioritize attributes that are most effective in separating the data into distinct classes.\n",
        "\n",
        "* By maximizing information gain, the algorithm aims to create a tree that is as accurate and efficient as possible.\n",
        "\n",
        "Therefore, Information gain is the key metric that drives the decision tree to create the most optimal tree structure."
      ],
      "metadata": {
        "id": "VEfuRpHHDuQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.What is the difference between Gini Impurity and Entropy ?\n",
        "\n",
        "Ans-6. While both Gini impurity and entropy serve the same fundamental purpose in decision trees—measuring the impurity or disorder of a dataset—they differ in their mathematical formulation and computational characteristics. Here's a breakdown of their key distinctions:\n",
        "\n",
        "1. **Mathematical Formulation:**\n",
        "\n",
        "* **Gini Impurity:**\n",
        "\n",
        "* Calculated as: 1 - Σ (p_i)^2, where p_i is the probability of an element belonging to class i.\n",
        "\n",
        "* It's a simpler, linear calculation.\n",
        "\n",
        "* **Entropy:**\n",
        "\n",
        "* Calculated as: - Σ pi * log2(pi), where pi is the probability of an element belonging to class i.\n",
        "\n",
        "* It involves a logarithmic calculation, making it slightly more complex.\n",
        "\n",
        "2. **Computational Complexity:**\n",
        "\n",
        "* **Gini Impurity:**\n",
        "\n",
        "* Generally faster to compute due to its linear nature.\n",
        "\n",
        "* **Entropy:**\n",
        "\n",
        "* More computationally intensive because of the logarithmic function.\n",
        "\n",
        "3. **Sensitivity:**\n",
        "\n",
        "* **Entropy:**\n",
        "\n",
        "* Slightly more sensitive to changes in class probabilities, especially when classes are close to evenly distributed.\n",
        "\n",
        "* **Gini Impurity:**\n",
        "\n",
        "* Can be slightly biased towards creating larger partitions.\n",
        "\n",
        "4. **Range of Values:**\n",
        "\n",
        "* **Gini Impurity:**\n",
        "\n",
        "* Ranges from 0 to 0.5.\n",
        "\n",
        "* **Entropy:**\n",
        "\n",
        "* Ranges from 0 to 1 (in binary classification).\n",
        "\n",
        "5. **Practical Implications:**\n",
        "\n",
        "* **Performance:**\n",
        "\n",
        "* In most practical applications, the difference in performance between decision trees using Gini impurity and those using entropy is often negligible.\n",
        "\n",
        "* **Choice:**\n",
        "\n",
        "* Gini impurity is often preferred for its computational efficiency, especially with large datasets.\n",
        "\n",
        "* Entropy is sometimes prefered when a higher level of precision is needed.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "* Both metrics aim to measure the same thing: how mixed the classes are within a dataset.\n",
        "\n",
        "* The primary difference lies in how they calculate this measure.\n",
        "\n",
        "* Gini impurity is generally faster, while entropy is slightly more nuanced.\n",
        "\n"
      ],
      "metadata": {
        "id": "KnrBbTkxEv5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.What is the mathematical explanation behind Decision Trees\t?\n",
        "\n",
        "Ans-7. Understanding the mathematical explanation behind decision trees involves grasping the core concepts that drive their construction and operation. Here's a breakdown of the key mathematical elements:\n",
        "\n",
        "1. **Core Concepts:**\n",
        "\n",
        "* **Information Theory:**\n",
        "\n",
        "* Decision trees heavily rely on information theory, particularly the concepts of entropy and information gain.\n",
        "\n",
        "* Entropy quantifies the impurity or disorder within a dataset.\n",
        "\n",
        "* Information gain measures the reduction in entropy achieved by splitting the dataset based on an attribute.\n",
        "\n",
        "* **Probability:**\n",
        "\n",
        "* Probability plays a crucial role in calculating entropy and Gini impurity.\n",
        "\n",
        "* These measures involve determining the probability of data points belonging to specific classes.\n",
        "\n",
        "* **Recursive Partitioning:**\n",
        "\n",
        "* The process of building a decision tree involves recursively partitioning the dataset into subsets.\n",
        "\n",
        "* This recursive process can be expressed mathematically through algorithmic functions.\n",
        "\n",
        "2. **Key Mathematical Elements:**\n",
        "\n",
        "* **Entropy:**\n",
        "\n",
        "* As discussed earlier, entropy is calculated using the formula:\n",
        "\n",
        "      H(S) = - Σ pi * log2(pi)\n",
        "\n",
        "* This formula quantifies the uncertainty associated with the distribution of class labels in a dataset.\n",
        "\n",
        "* **Gini Impurity:**\n",
        "\n",
        "* Gini impurity is calculated using the formula:\n",
        "\n",
        "      Gini = 1 - Σ (p_i)^2\n",
        "\n",
        "* This formula measures the probability of incorrectly classifying a randomly chosen element.\n",
        "\n",
        "* **Information Gain:**\n",
        "\n",
        "* Information gain is calculated as the difference between the entropy of the parent node and the weighted average entropy of the child nodes:\n",
        "\n",
        "      Gain(S, A) = Entropy(S) - Σ (|Sv| / |S|) * Entropy(Sv)\n",
        "\n",
        "Where:\n",
        "\n",
        "* S is the parent node.\n",
        "\n",
        "* A is the attribute being used for splitting.\n",
        "\n",
        "* Sv are the child nodes.\n",
        "\n",
        "* |S| and |Sv| represent the number of samples in the respective nodes.\n",
        "\n",
        "* **Algorithmic Optimization:**\n",
        "\n",
        "* Decision tree algorithms aim to optimize the tree structure by selecting the splits that maximize information gain or minimize Gini impurity.\n",
        "\n",
        "* This optimization process involves evaluating numerous potential splits and choosing the best one.\n",
        "\n",
        "3. **Practical Implications:**\n",
        "\n",
        "* **Attribute Selection:**\n",
        "\n",
        "* The mathematical formulas for entropy, Gini impurity, and information gain provide a quantitative basis for selecting the most informative attributes for splitting the data.\n",
        "\n",
        "* **Tree Pruning:**\n",
        "\n",
        "* Mathematical criteria are also used in tree pruning, which involves removing branches that do not significantly improve the model's accuracy. This helps to prevent overfitting.\n",
        "\n",
        "* **Model Evaluation:**\n",
        "\n",
        "* Mathematical metrics, such as accuracy, precision, recall, and F1-score, are used to evaluate the performance of decision tree models.\n",
        "\n",
        "**In essence,** the mathematics behind decision trees provides a rigorous framework for building and optimizing these models. By leveraging concepts from information theory and probability, decision tree algorithms can effectively learn patterns from data and make accurate predictions."
      ],
      "metadata": {
        "id": "Gn--MSUPGA8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8.What is Pre-Pruning in Decision Trees ?\n",
        "\n",
        "Ans-8. In the realm of decision trees, \"pre-pruning\" is a technique used to prevent overfitting by halting the construction of the tree early. Here's a breakdown:\n",
        "\n",
        "Understanding Pre-Pruning:\n",
        "\n",
        "Early Stopping:\n",
        "Pre-pruning, also known as \"early stopping,\" involves stopping the growth of the decision tree during its construction.\n",
        "This is done by setting certain criteria that, when met, prevent further splitting of nodes.\n",
        "Preventing Overfitting:\n",
        "Decision trees have a tendency to overfit the training data, meaning they become too complex and memorize noise rather than learning generalizable patterns.\n",
        "Pre-pruning aims to avoid this by limiting the tree's depth and complexity.\n",
        "How It Works:\n",
        "During the tree-building process, the algorithm checks certain conditions before each split.\n",
        "If a condition is met, the split is not performed, and the node becomes a leaf.\n",
        "Common Pre-Pruning Techniques:\n",
        "\n",
        "Maximum Depth:\n",
        "Limiting the maximum depth of the tree.\n",
        "Minimum Samples per Leaf:\n",
        "Setting a minimum number of data points required in a leaf node.\n",
        "Minimum Samples per Split:\n",
        "Specifying the minimum number of data points required to split an internal node.\n",
        "Minimum Impurity Decrease:\n",
        "Stopping a split if the decrease in impurity (e.g., Gini impurity or entropy) is below a certain threshold.\n",
        "Key Advantages:\n",
        "\n",
        "Computational Efficiency:\n",
        "Pre-pruning can be faster than post-pruning because it avoids building a fully grown tree.\n",
        "Simpler Models:\n",
        "It results in simpler, more interpretable decision trees.\n",
        "Key Disadvantages:\n",
        "\n",
        "Potential Underfitting:\n",
        "If the pruning criteria are too strict, the tree may stop growing too early, leading to underfitting.\n",
        "It is possible that a split that appears to be of little value at the time, may lead to very valuable splits further down the tree. Pre-pruning can prevent those future valuable splits from happening.\n",
        "In essence, pre-pruning is a proactive approach to preventing overfitting by setting constraints on the tree's growth during its construction.\n"
      ],
      "metadata": {
        "id": "X6uCG5tYIFvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.What is Post-Pruning in Decision Trees ?\n",
        "\n",
        "Ans-9. In the context of decision trees, post-pruning is a technique used to reduce the complexity of a fully grown tree to prevent overfitting. Here's a breakdown:\n",
        "\n",
        "**Understanding the Problem:**\n",
        "\n",
        "* **Overfitting:** Decision trees, if allowed to grow to their full depth, can become excessively complex. This means they start to \"memorize\" the training data, including its noise, rather than learning the underlying patterns. This leads to poor performance on new, unseen data.\n",
        "\n",
        "####What Post-Pruning Does:\n",
        "\n",
        "* **Post-pruning involves:**\n",
        "\n",
        "* First, growing the decision tree to its maximum possible depth.\n",
        "Then, \"pruning\" or removing branches that do not contribute significantly to the tree's predictive accuracy.\n",
        "\n",
        "* The goal is to simplify the tree, making it more general and better able to handle new data.\n",
        "\n",
        "####Key Aspects:\n",
        "\n",
        "* **How it works:**\n",
        "\n",
        "* The process typically involves evaluating the impact of removing branches on a validation dataset.\n",
        "\n",
        "* Branches are removed if their removal does not significantly increase the error on the validation set, or if they reduce the model's complexity without a significant loss of accuracy.\n",
        "\n",
        "* **Why it's used:**\n",
        "\n",
        "* To improve the generalization of the decision tree.\n",
        "\n",
        "* To reduce the risk of overfitting.\n",
        "\n",
        "* **Techniques:**\n",
        "\n",
        "* Common post-pruning techniques include cost-complexity pruning and reduced error pruning.\n",
        "\n",
        "In essence, post-pruning allows the decision tree to \"learn\" as much as possible from the training data, and then it refines that learning by removing unnecessary details."
      ],
      "metadata": {
        "id": "GgaZtkGVxIv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10.What is the difference between Pre-Pruning and Post-Pruning ?\n",
        "\n",
        "Ans-10. The key difference between pre-pruning and post-pruning lies in when the pruning process occurs during the creation of a decision tree. Here's a breakdown:\n",
        "\n",
        "##**Pre-Pruning (Early Stopping):**\n",
        "\n",
        "* **When:**\n",
        "\n",
        "* This technique stops the growth of the decision tree before it fully develops. It halts the process early, preventing the tree from becoming too complex.\n",
        "\n",
        "* **How:**\n",
        "\n",
        "* Pre-pruning sets constraints or conditions that determine when to stop splitting nodes. These conditions might include:\n",
        "\n",
        "* Maximum tree depth.\n",
        "\n",
        "* Minimum number of samples required to split a node.\n",
        "\n",
        "* Minimum number of samples required in a leaf node.\n",
        "\n",
        "* A threshold for information gain.\n",
        "\n",
        "* **Goal:**\n",
        "\n",
        "* To prevent overfitting by stopping the tree from growing to a point where it memorizes noise in the training data.\n",
        "\n",
        "* **Advantages:**\n",
        "\n",
        "* Can be computationally efficient.\n",
        "\n",
        "* Reduces the risk of overfitting.\n",
        "\n",
        "* **Disadvantages:**\n",
        "\n",
        "* May lead to underfitting if the stopping criteria are too strict, preventing the tree from capturing important patterns.\n",
        "\n",
        "##**Post-Pruning:**\n",
        "\n",
        "* **When:**\n",
        "\n",
        "* This technique involves growing the decision tree to its full depth and then removing branches that do not contribute significantly to its accuracy.\n",
        "\n",
        "* **How:**\n",
        "\n",
        "* After the tree is fully grown, post-pruning evaluates the impact of removing branches on a validation dataset.\n",
        "\n",
        "* Branches are removed if their removal does not significantly increase the error rate.\n",
        "\n",
        "* **Goal:**\n",
        "\n",
        "* To simplify a fully grown tree and improve its generalization to unseen data, thereby reducing overfitting.\n",
        "\n",
        "* **Advantages:**\n",
        "\n",
        "* Often leads to better generalization than pre-pruning.\n",
        "\n",
        "* Allows the tree to explore all potential patterns before simplification.\n",
        "\n",
        "* **Disadvantages:**\n",
        "\n",
        "* Can be computationally expensive, as it requires growing the full tree first.\n",
        "\n",
        "* Requires a validation set.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "* Pre-pruning stops the tree from growing too much.\n",
        "\n",
        "* Post-pruning trims a fully grown tree.\n",
        "\n",
        "Both methods aim to prevent overfitting, but they approach the problem from different angles."
      ],
      "metadata": {
        "id": "Y60XbAzG_t4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11.What is a Decision Tree Regressor ?\n",
        "\n",
        "Ans-11. A Decision Tree Regressor is a type of machine learning algorithm that uses a tree-like structure to predict continuous numerical values. Here's a breakdown:\n",
        "\n",
        "####**Core Concept:**\n",
        "\n",
        "**Regression vs. Classification:**\n",
        "\n",
        "* Decision trees can be used for both classification (predicting categories) and regression (predicting numerical values).\n",
        "\n",
        "* A Decision Tree Regressor is specifically designed for regression tasks.\n",
        "\n",
        "**Tree Structure:**\n",
        "\n",
        "* Like all decision trees, it consists of nodes and branches.\n",
        "\n",
        "* Internal nodes represent decisions based on features (e.g., \"Is the house size greater than 1500 sq ft?\").\n",
        "\n",
        "* Branches represent the outcomes of those decisions.\n",
        "\n",
        "* Leaf nodes represent the predicted numerical values.\n",
        "\n",
        "**How it Works:**\n",
        "\n",
        "* The algorithm recursively partitions the data into smaller subsets based on the features.\n",
        "\n",
        "* At each split, it aims to minimize the variance or mean squared error (MSE) within the resulting subsets.\n",
        "\n",
        "* When a data point reaches a leaf node, the predicted value is typically the average of the target values in that node.\n",
        "\n",
        "**Key Characteristics:**\n",
        "\n",
        "**Predicting Continuous Values:**\n",
        "\n",
        "* Its primary purpose is to predict values that can fall anywhere on a continuous scale (e.g., house prices, temperature, sales figures).\n",
        "\n",
        "**Non-linear Relationships:**\n",
        "\n",
        "* Decision Tree Regressors can capture complex, non-linear relationships between features and the target variable.\n",
        "\n",
        "* **Interpretability:**\n",
        "\n",
        "* The tree structure makes it relatively easy to understand how the model arrives at its predictions.\n",
        "\n",
        "* **Overfitting:**\n",
        "\n",
        "* Like all decision trees, they are prone to overfitting, which means they can memorize the training data and perform poorly on new data. Techniques like pruning are used to mitigate this.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "A Decision Tree Regressor is a valuable tool for predicting numerical values, especially when the relationships between variables are complex and non-linear.\n"
      ],
      "metadata": {
        "id": "yuKRsZ2vBI-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12.What are the advantages and disadvantages of Decision Trees ?\n",
        "\n",
        "Ans-12. Decision trees are a popular and versatile machine learning algorithm, but like any tool, they have their strengths and weaknesses. Here's a summary of their advantages and disadvantages:\n",
        "\n",
        "####**Advantages:**\n",
        "\n",
        "* **Interpretability:**\n",
        "\n",
        "* Decision trees are easy to visualize and understand. The tree structure clearly shows the decision-making process, making it simple to explain how the model arrives at its predictions.\n",
        "\n",
        "* **Versatility:**\n",
        "\n",
        "* They can handle both classification and regression tasks.\n",
        "\n",
        "* They can work with both categorical and numerical data.\n",
        "\n",
        "* **Minimal Data Preparation:**\n",
        "\n",
        "* Decision trees require relatively little data preprocessing. They are less sensitive to outliers and missing values than some other algorithms.\n",
        "\n",
        "* They do not require data normalization or scaling.\n",
        "\n",
        "* **Non-linear Relationships:**\n",
        "\n",
        "* Decision trees can capture complex, non-linear relationships between features and the target variable.\n",
        "\n",
        "* **White Box Model:**\n",
        "\n",
        "* The reasoning behind predictions are easily explainable.\n",
        "\n",
        "####Disadvantages:\n",
        "\n",
        "* **Overfitting:**\n",
        "\n",
        "* Decision trees are prone to overfitting, especially when they are allowed to grow too deep. This means they can memorize the training data and perform poorly on new data.\n",
        "\n",
        "* **Instability:**\n",
        "\n",
        "* Small changes in the training data can lead to significant changes in the tree structure. This can make the model unstable.\n",
        "\n",
        "* **Bias with Imbalanced Data:**\n",
        "\n",
        "* If the dataset is imbalanced (i.e., one class has significantly more samples than the others), decision trees can be biased towards the majority class.\n",
        "\n",
        "* **Greedy Algorithm:**\n",
        "\n",
        "* Decision tree algorithms typically use a greedy approach, which means they make locally optimal decisions at each node. This can lead to suboptimal overall trees.\n",
        "\n",
        "* **Can be computationally expensive:**\n",
        "\n",
        "* Especially with very large datasets.\n",
        "\n",
        "####Key Considerations:\n",
        "\n",
        "* Techniques like pruning and ensemble methods (e.g., Random Forests, Gradient Boosting) can help mitigate some of the disadvantages of decision trees, such as overfitting and instability.\n",
        "\n",
        "**In essence,** decision trees are powerful tools when used appropriately. Understanding their strengths and weaknesses is crucial for effective model building."
      ],
      "metadata": {
        "id": "GFCYsW3Bso9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13.How does a Decision Tree handle missing values ?\n",
        "\n",
        "Ans-13. Decision trees possess some inherent capabilities for handling missing values, which contributes to their robustness in real-world scenarios. Here's a breakdown of how they typically approach this issue:\n",
        "\n",
        "####**Key Strategies:**\n",
        "\n",
        "**During Tree Construction:**\n",
        "\n",
        "* **Weighted Impurity Calculations:**\n",
        "\n",
        "* When evaluating potential splits, decision tree algorithms (like CART) can adjust their impurity calculations (e.g., Gini impurity) to account for missing values. This involves weighting the contributions of instances based on the proportion of available data.\n",
        "\n",
        "* **Surrogate Splits:**\n",
        "\n",
        "* A significant technique is the use of surrogate splits. When a primary splitting feature has missing values, the algorithm can utilize secondary, \"surrogate\" features that exhibit similar splitting patterns. This allows the tree to make decisions even when the primary feature is unavailable.\n",
        "\n",
        "* **Handling During Node Splitting:**\n",
        "\n",
        "* When the algorithm is determining the best split, it considers all the available data. Therefore the presence of some missing data, does not prevent the algorithm from finding a good split within the remaining data.\n",
        "\n",
        "* **During Prediction:**\n",
        "\n",
        "* **Following Surrogate Splits:**\n",
        "\n",
        "* When a data point with a missing value encounters a node where the splitting feature is missing, the tree can follow the pre-calculated surrogate splits to determine the appropriate branch.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "* Decision trees aim to leverage the available information as effectively as possible.\n",
        "\n",
        "* They do not necessarily require explicit imputation before training, although in some cases, preprocessing may improve performance.\n",
        "\n",
        "* By using weighted impurity calculations, and surrogate splits, they are able to work around the absense of certain data within a data point.\n",
        "\n",
        "This adaptability makes decision trees valuable in situations where datasets are prone to missing data.\n"
      ],
      "metadata": {
        "id": "bqxc0vBHuCbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14.How does a Decision Tree handle categorical features ?\n",
        "\n",
        "Ans-14. Decision trees can handle categorical features, but the way they do so can vary depending on the specific algorithm and implementation. Here's a breakdown of the common approaches:\n",
        "\n",
        "####Understanding the Challenge:\n",
        "\n",
        "* Categorical features represent data with distinct categories (e.g., colors, types, locations), not numerical values.\n",
        "\n",
        "* Decision trees work by splitting data based on feature values, so they need a way to determine the \"best\" split for categorical features.\n",
        "\n",
        "####Common Approaches:\n",
        "\n",
        "* **Direct Splitting:**\n",
        "\n",
        "* Some decision tree algorithms can directly handle categorical features by creating splits based on subsets of categories.\n",
        "\n",
        "* For example, a node might split on the \"color\" feature, with one branch for \"red\" and \"blue\" and another branch for \"green.\"\n",
        "\n",
        "* This approach involves evaluating the impurity (e.g., Gini impurity, entropy) of the resulting subsets for different combinations of categories.\n",
        "\n",
        "####Encoding:\n",
        "\n",
        "* Often, categorical features are transformed into numerical representations before being used in a decision tree. Common encoding techniques include:\n",
        "\n",
        "* **Label Encoding:**\n",
        "\n",
        "* Assigns a unique numerical value to each category. This is simple but can introduce unintended ordinal relationships between categories.\n",
        "\n",
        "* **One-Hot Encoding:**\n",
        "\n",
        "* Creates a binary column for each category, indicating whether a data point belongs to that category. This avoids ordinal relationships but can increase the dimensionality of the data.\n",
        "\n",
        "* **Ordinal Encoding:**\n",
        "\n",
        "* When categorical data has a natural ordering, this encoding assigns numerical values that respect that order.\n",
        "\n",
        "* Once encoded, the decision tree can treat the categorical features as numerical and use standard splitting criteria.\n",
        "\n",
        "* **Handling in specific algorithms:**\n",
        "\n",
        "* It is worth noting that some modern algorithms, such as CatBoost, are designed to handle categorical variables directly, without the need for extensive preprocessing. These algorithms can often achieve better performance with categorical data.\n",
        "\n",
        "####Key Considerations:\n",
        "\n",
        "* The choice of approach can impact the performance and interpretability of the decision tree.\n",
        "\n",
        "* One-hot encoding can be particularly useful when dealing with nominal categorical features (categories with no inherent order).\n",
        "\n",
        "* It's important to be aware of the potential for increased dimensionality when using one-hot encoding, especially with high-cardinality categorical features (features with many unique categories).\n",
        "\n",
        "In summary, decision trees have various ways to deal with categorical data. The best method depends on the specific dataset and the goals of the analysis.\n"
      ],
      "metadata": {
        "id": "I-RaIotVuzyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15.What are some real-world applications of Decision Trees ?\n",
        "\n",
        "Ans-15. Decision trees are incredibly versatile and find applications across a wide range of industries. Here are some key real-world examples:\n",
        "\n",
        "##1. **Healthcare:**\n",
        "\n",
        "* **Medical Diagnosis:**\n",
        "\n",
        "* Decision trees can assist in diagnosing diseases by analyzing patient symptoms, medical history, and test results. They can help identify potential conditions and guide treatment decisions.\n",
        "\n",
        "* **Risk Assessment:**\n",
        "\n",
        "* They can be used to assess patient risk for developing certain conditions, such as heart disease or diabetes, based on various factors.\n",
        "\n",
        "##2. **Finance:**\n",
        "\n",
        "* **Credit Scoring:**\n",
        "\n",
        "* Banks and financial institutions use decision trees to evaluate the creditworthiness of loan applicants. Factors like income, credit history, and debt levels are analyzed to determine the likelihood of loan repayment.\n",
        "\n",
        "* **Fraud Detection:**\n",
        "\n",
        "* Decision trees can identify suspicious patterns in financial transactions, helping to detect fraudulent activities.\n",
        "\n",
        "##3. **Marketing:**\n",
        "\n",
        "* **Customer Relationship Management (CRM):**\n",
        "\n",
        "* Businesses use decision trees to segment customers based on their demographics, purchasing behavior, and other factors. This allows for targeted marketing campaigns and personalized offers.\n",
        "\n",
        "* **Customer Churn Prediction:**\n",
        "\n",
        "* Companies can predict which customers are likely to stop using their products or services, enabling them to take proactive measures to retain them.\n",
        "\n",
        "##4. **Quality Control:**\n",
        "\n",
        "* **Manufacturing:**\n",
        "\n",
        "* Decision trees can be used to identify factors that contribute to product defects, helping to improve manufacturing processes and ensure product quality.\n",
        "\n",
        "##5. **Recommendation Systems:**\n",
        "\n",
        "* **E-commerce and Entertainment:**\n",
        "\n",
        "* Platforms like online retailers and streaming services use decision trees as part of their recommendation algorithms. They analyze user preferences and past behavior to suggest relevant products or content.\n",
        "\n",
        "##6. **General Decision Making:**\n",
        "\n",
        "* Decision trees are very useful for general decision making processes. Because of their visual nature, they can be used to map out the possible outcomes of differing choices.\n",
        "\n",
        "**In essence,** the ability of decision trees to handle both categorical and numerical data, combined with their interpretability, makes them a valuable tool in numerous fields.\n"
      ],
      "metadata": {
        "id": "XXW_vTAfwNfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "U3-TIriCxUQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16.Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy."
      ],
      "metadata": {
        "id": "U9OFgnWcxfOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m7zCiseyKdR",
        "outputId": "b462d913-61e3-4749-b363-c0c218a21940"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###17.Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances."
      ],
      "metadata": {
        "id": "i83V00ubxvXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Classifier with 'gini' criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print the feature importances\n",
        "feature_names = iris.feature_names\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(feature_names, clf.feature_importances_):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGEtMzZ2x3Rm",
        "outputId": "4d2944f5-5399-423c-c14e-86a31dc8161b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###18.Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy."
      ],
      "metadata": {
        "id": "aEOWJVAUyXaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Classifier with 'entropy' criterion\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZWsdCWcygmQ",
        "outputId": "178604ae-733a-47b3-fbb4-93a4306b74ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###19.Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "trXCzErEymPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate and print Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucw8nN-CysZ9",
        "outputId": "e5450942-0a22-40b1-8f17-a49d226d3a88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###20.Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz."
      ],
      "metadata": {
        "id": "RbsJcSjyy1Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Visualize the tree\n",
        "dot_data = export_graphviz(\n",
        "    clf,\n",
        "    out_file=None,\n",
        "    feature_names=iris.feature_names,\n",
        "    class_names=iris.target_names,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")  # Saves the tree visualization as a file (e.g., decision_tree.pdf)\n",
        "\n",
        "# To view the visualization inline (e.g., in Jupyter Notebook), use:\n",
        "# graph.view()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x_KMlLAcy6yq",
        "outputId": "ba6fa822-344b-49f4-ae81-0729185c0c84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###21.Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree."
      ],
      "metadata": {
        "id": "T_1DL0Gsy7hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier with maximum depth of 3\n",
        "limited_depth_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "limited_depth_clf.fit(X_train, y_train)\n",
        "\n",
        "# Train a fully grown Decision Tree Classifier\n",
        "fully_grown_clf = DecisionTreeClassifier(random_state=42)  # No max_depth, grows fully\n",
        "fully_grown_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate accuracies\n",
        "limited_depth_y_pred = limited_depth_clf.predict(X_test)\n",
        "limited_depth_accuracy = accuracy_score(y_test, limited_depth_y_pred)\n",
        "\n",
        "fully_grown_y_pred = fully_grown_clf.predict(X_test)\n",
        "fully_grown_accuracy = accuracy_score(y_test, fully_grown_y_pred)\n",
        "\n",
        "# Print accuracies\n",
        "print(f\"Accuracy with max_depth=3: {limited_depth_accuracy:.2f}\")\n",
        "print(f\"Accuracy with fully grown tree: {fully_grown_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBYlzHwgzD0g",
        "outputId": "539013af-7962-4b5b-941b-7c70ae7b20b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=3: 1.00\n",
            "Accuracy with fully grown tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###22.Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree."
      ],
      "metadata": {
        "id": "KDNhnxhQzH19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the default Decision Tree Classifier\n",
        "default_clf = DecisionTreeClassifier(random_state=42)\n",
        "default_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate accuracy for the default classifier\n",
        "default_y_pred = default_clf.predict(X_test)\n",
        "default_accuracy = accuracy_score(y_test, default_y_pred)\n",
        "\n",
        "# Create and train the Decision Tree Classifier with min_samples_split=5\n",
        "custom_clf = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "custom_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate accuracy for the custom classifier\n",
        "custom_y_pred = custom_clf.predict(X_test)\n",
        "custom_accuracy = accuracy_score(y_test, custom_y_pred)\n",
        "\n",
        "# Print both accuracies\n",
        "print(f\"Default Decision Tree Accuracy: {default_accuracy:.2f}\")\n",
        "print(f\"Custom Decision Tree (min_samples_split=5) Accuracy: {custom_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpMQmWm-zNdM",
        "outputId": "7c49d586-9ed5-46f8-f1ba-e1dfbd1d6e87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Decision Tree Accuracy: 1.00\n",
            "Custom Decision Tree (min_samples_split=5) Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###23.Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data."
      ],
      "metadata": {
        "id": "ws4LTr-VzrBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the classifier on unscaled data\n",
        "clf_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = clf_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# Apply feature scaling to the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the classifier on scaled data\n",
        "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the comparison of accuracies\n",
        "print(f\"Accuracy with unscaled data: {accuracy_unscaled:.2f}\")\n",
        "print(f\"Accuracy with scaled data: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaU3jHfmzyWO",
        "outputId": "0470b1cf-f36c-4dad-b3f8-ff7946e0b777"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with unscaled data: 1.00\n",
            "Accuracy with scaled data: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###24.Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification."
      ],
      "metadata": {
        "id": "Enpc5u0oz7by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Classifier and wrap it with OneVsRestClassifier\n",
        "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate accuracy\n",
        "y_pred = ovr_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model accuracy (OvR with Decision Tree Classifier): {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL7vgMgU0Ff1",
        "outputId": "1521a384-27b1-49e4-8548-9cc1a0d41fb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy (OvR with Decision Tree Classifier): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###25.Write a Python program to train a Decision Tree Classifier and display the feature importance scores."
      ],
      "metadata": {
        "id": "IJt6r9nC0K5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Display feature importance scores\n",
        "feature_importances = clf.feature_importances_\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(feature_names, feature_importances):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vhXee0x0Rd3",
        "outputId": "7c43ea02-5133-4921-ec6a-58f4e03dd369"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "sepal length (cm): 0.0133\n",
            "sepal width (cm): 0.0000\n",
            "petal length (cm): 0.5641\n",
            "petal width (cm): 0.4226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###26.Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree."
      ],
      "metadata": {
        "id": "D3ZrxVMt0aQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor with max_depth=5\n",
        "limited_depth_regressor = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "limited_depth_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate performance of the limited depth model\n",
        "limited_depth_y_pred = limited_depth_regressor.predict(X_test)\n",
        "limited_depth_mse = mean_squared_error(y_test, limited_depth_y_pred)\n",
        "\n",
        "# Train an unrestricted Decision Tree Regressor\n",
        "unrestricted_regressor = DecisionTreeRegressor(random_state=42)  # No max_depth specified\n",
        "unrestricted_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate performance of the unrestricted model\n",
        "unrestricted_y_pred = unrestricted_regressor.predict(X_test)\n",
        "unrestricted_mse = mean_squared_error(y_test, unrestricted_y_pred)\n",
        "\n",
        "# Print the comparison of Mean Squared Error\n",
        "print(f\"Mean Squared Error (max_depth=5): {limited_depth_mse:.2f}\")\n",
        "print(f\"Mean Squared Error (unrestricted): {unrestricted_mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awkN0rId0jq-",
        "outputId": "40f05adf-60c4-4c1e-c14c-ceb3eb268a6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (max_depth=5): 0.52\n",
            "Mean Squared Error (unrestricted): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###27.Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy."
      ],
      "metadata": {
        "id": "yFx6JtKA0pPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier to extract the cost complexity pruning path\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the pruning path (ccp_alphas and impurities)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas  # Effective alphas\n",
        "impurities = path.impurities  # Node impurities\n",
        "\n",
        "# Train Decision Tree models for different values of ccp_alpha and collect accuracies\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate accuracies on training and test sets\n",
        "    train_accuracies.append(accuracy_score(y_train, clf.predict(X_train)))\n",
        "    test_accuracies.append(accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "# Plot the effect of CCP on accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, train_accuracies, marker='o', label='Train Accuracy', drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas, test_accuracies, marker='o', label='Test Accuracy', drawstyle=\"steps-post\")\n",
        "plt.xlabel(\"Effective Alpha (ccp_alpha)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of CCP (Cost Complexity Pruning) on Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "2TSh6hP20yes",
        "outputId": "47677e2e-0ea4-4908-c030-46b1e6345557"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###28.Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "ADZBDTW504xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using Precision, Recall, and F1-Score\n",
        "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "print(\"Performance Metrics:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5GQSDFN1CvY",
        "outputId": "f2aeaab0-4827-4bfb-bb68-345b5a44ef94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###29.Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn."
      ],
      "metadata": {
        "id": "KkPSlSmV1OGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "GAtS-uR_1URV",
        "outputId": "fdaa22f0-4a11-4f30-e584-70dd822c30fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###30.Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split."
      ],
      "metadata": {
        "id": "6FUp6aS91ct9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],  # Try different depths or no restriction\n",
        "    'min_samples_split': [2, 5, 10, 20]  # Minimum samples required to split\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV to find the optimal parameters\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred = best_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Test Accuracy of the Best Model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJhO4MuG1lEx",
        "outputId": "bae210b7-341e-4b10-a1d5-574e7cc3bd83"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Test Accuracy of the Best Model: 1.00\n"
          ]
        }
      ]
    }
  ]
}